{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JMIWoTMT0sI",
        "colab_type": "code",
        "outputId": "40a9f45b-7e61-4605-cf63-6e3f9738f08c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "! git clone --recursive https://github.com/ayushbaid/cloudy-cycle-gans.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloudy-cycle-gans'...\n",
            "remote: Enumerating objects: 241, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/241)\u001b[K\rremote: Counting objects:   1% (3/241)\u001b[K\rremote: Counting objects:   2% (5/241)\u001b[K\rremote: Counting objects:   3% (8/241)\u001b[K\rremote: Counting objects:   4% (10/241)\u001b[K\rremote: Counting objects:   5% (13/241)\u001b[K\rremote: Counting objects:   6% (15/241)\u001b[K\rremote: Counting objects:   7% (17/241)\u001b[K\rremote: Counting objects:   8% (20/241)\u001b[K\rremote: Counting objects:   9% (22/241)\u001b[K\rremote: Counting objects:  10% (25/241)\u001b[K\rremote: Counting objects:  11% (27/241)\u001b[K\rremote: Counting objects:  12% (29/241)\u001b[K\rremote: Counting objects:  13% (32/241)\u001b[K\rremote: Counting objects:  14% (34/241)\u001b[K\rremote: Counting objects:  15% (37/241)\u001b[K\rremote: Counting objects:  16% (39/241)\u001b[K\rremote: Counting objects:  17% (41/241)\u001b[K\rremote: Counting objects:  18% (44/241)\u001b[K\rremote: Counting objects:  19% (46/241)\u001b[K\rremote: Counting objects:  20% (49/241)\u001b[K\rremote: Counting objects:  21% (51/241)\u001b[K\rremote: Counting objects:  22% (54/241)\u001b[K\rremote: Counting objects:  23% (56/241)\u001b[K\rremote: Counting objects:  24% (58/241)\u001b[K\rremote: Counting objects:  25% (61/241)\u001b[K\rremote: Counting objects:  26% (63/241)\u001b[K\rremote: Counting objects:  27% (66/241)\u001b[K\rremote: Counting objects:  28% (68/241)\u001b[K\rremote: Counting objects:  29% (70/241)\u001b[K\rremote: Counting objects:  30% (73/241)\u001b[K\rremote: Counting objects:  31% (75/241)\u001b[K\rremote: Counting objects:  32% (78/241)\u001b[K\rremote: Counting objects:  33% (80/241)\u001b[K\rremote: Counting objects:  34% (82/241)\u001b[K\rremote: Counting objects:  35% (85/241)\u001b[K\rremote: Counting objects:  36% (87/241)\u001b[K\rremote: Counting objects:  37% (90/241)\u001b[K\rremote: Counting objects:  38% (92/241)\u001b[K\rremote: Counting objects:  39% (94/241)\u001b[K\rremote: Counting objects:  40% (97/241)\u001b[K\rremote: Counting objects:  41% (99/241)\u001b[K\rremote: Counting objects:  42% (102/241)\u001b[K\rremote: Counting objects:  43% (104/241)\u001b[K\rremote: Counting objects:  44% (107/241)\u001b[K\rremote: Counting objects:  45% (109/241)\u001b[K\rremote: Counting objects:  46% (111/241)\u001b[K\rremote: Counting objects:  47% (114/241)\u001b[K\rremote: Counting objects:  48% (116/241)\u001b[K\rremote: Counting objects:  49% (119/241)\u001b[K\rremote: Counting objects:  50% (121/241)\u001b[K\rremote: Counting objects:  51% (123/241)\u001b[K\rremote: Counting objects:  52% (126/241)\u001b[K\rremote: Counting objects:  53% (128/241)\u001b[K\rremote: Counting objects:  54% (131/241)\u001b[K\rremote: Counting objects:  55% (133/241)\u001b[K\rremote: Counting objects:  56% (135/241)\u001b[K\rremote: Counting objects:  57% (138/241)\u001b[K\rremote: Counting objects:  58% (140/241)\u001b[K\rremote: Counting objects:  59% (143/241)\u001b[K\rremote: Counting objects:  60% (145/241)\u001b[K\rremote: Counting objects:  61% (148/241)\u001b[K\rremote: Counting objects:  62% (150/241)\u001b[K\rremote: Counting objects:  63% (152/241)\u001b[K\rremote: Counting objects:  64% (155/241)\u001b[K\rremote: Counting objects:  65% (157/241)\u001b[K\rremote: Counting objects:  66% (160/241)\u001b[K\rremote: Counting objects:  67% (162/241)\u001b[K\rremote: Counting objects:  68% (164/241)\u001b[K\rremote: Counting objects:  69% (167/241)\u001b[K\rremote: Counting objects:  70% (169/241)\u001b[K\rremote: Counting objects:  71% (172/241)\u001b[K\rremote: Counting objects:  72% (174/241)\u001b[K\rremote: Counting objects:  73% (176/241)\u001b[K\rremote: Counting objects:  74% (179/241)\u001b[K\rremote: Counting objects:  75% (181/241)\u001b[K\rremote: Counting objects:  76% (184/241)\u001b[K\rremote: Counting objects:  77% (186/241)\u001b[K\rremote: Counting objects:  78% (188/241)\u001b[K\rremote: Counting objects:  79% (191/241)\u001b[K\rremote: Counting objects:  80% (193/241)\u001b[K\rremote: Counting objects:  81% (196/241)\u001b[K\rremote: Counting objects:  82% (198/241)\u001b[K\rremote: Counting objects:  83% (201/241)\u001b[K\rremote: Counting objects:  84% (203/241)\u001b[K\rremote: Counting objects:  85% (205/241)\u001b[K\rremote: Counting objects:  86% (208/241)\u001b[K\rremote: Counting objects:  87% (210/241)\u001b[K\rremote: Counting objects:  88% (213/241)\u001b[K\rremote: Counting objects:  89% (215/241)\u001b[K\rremote: Counting objects:  90% (217/241)\u001b[K\rremote: Counting objects:  91% (220/241)\u001b[K\rremote: Counting objects:  92% (222/241)\u001b[K\rremote: Counting objects:  93% (225/241)\u001b[K\rremote: Counting objects:  94% (227/241)\u001b[K\rremote: Counting objects:  95% (229/241)\u001b[K\rremote: Counting objects:  96% (232/241)\u001b[K\rremote: Counting objects:  97% (234/241)\u001b[K\rremote: Counting objects:  98% (237/241)\u001b[K\rremote: Counting objects:  99% (239/241)\u001b[K\rremote: Counting objects: 100% (241/241)\u001b[K\rremote: Counting objects: 100% (241/241), done.\u001b[K\n",
            "remote: Compressing objects: 100% (240/240), done.\u001b[K\n",
            "remote: Total 29843 (delta 1), reused 238 (delta 1), pack-reused 29602\u001b[K\n",
            "Receiving objects: 100% (29843/29843), 1.63 GiB | 39.60 MiB/s, done.\n",
            "Resolving deltas: 100% (151/151), done.\n",
            "Checking out files: 100% (10517/10517), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTvhEdbCT_eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports and initializations\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms, transforms, utils\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afbgzTNsWM3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cd '/content/cloudy-cycle-gans/data_small/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5UFYu1JVEwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataSet:    \n",
        "    data_dir = None\n",
        "\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "    @staticmethod\n",
        "    def initDataLoaders(data_dir, batch_size):\n",
        "        data_transforms = DataSet.setUpDataLoaderTransformers()\n",
        "        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                                  data_transforms[x])\n",
        "                          for x in ['train', 'val', 'test']}\n",
        "        dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "                                                      batch_size=batch_size,\n",
        "                                                      shuffle=True, num_workers=4)\n",
        "                      for x in ['train', 'val']}\n",
        "        dataloaders['test'] = torch.utils.data.DataLoader(image_datasets['test'],\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          shuffle=False, num_workers=4)\n",
        "        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "        class_names = image_datasets['train'].classes\n",
        "        return dataloaders, dataset_sizes, class_names\n",
        "\n",
        "    @staticmethod\n",
        "    def setUpDataLoaderTransformers(inputSize = 224):\n",
        "                \n",
        "        data_transforms = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(inputSize),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(inputSize),\n",
        "                transforms.CenterCrop(inputSize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "            'test': transforms.Compose([\n",
        "                transforms.Resize(inputSize),\n",
        "                transforms.CenterCrop(inputSize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "        }\n",
        "        return data_transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBDsYx6YV95C",
        "colab_type": "code",
        "outputId": "ecd6c247-8e4c-4954-93f0-caefc5244eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "data_dir = '/content/cloudy-cycle-gans/data_small/'\n",
        "DataSet.initDataLoaders(data_dir, 8)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'test': <torch.utils.data.dataloader.DataLoader at 0x7f6134e90c88>,\n",
              "  'train': <torch.utils.data.dataloader.DataLoader at 0x7f61a12b3978>,\n",
              "  'val': <torch.utils.data.dataloader.DataLoader at 0x7f617f6d01d0>},\n",
              " {'test': 1500, 'train': 7000, 'val': 1500},\n",
              " ['cloudy', 'sunny'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMwhecmYdFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import copy\n",
        "import sklearn.metrics\n",
        "\n",
        "class Classifier:\n",
        "    \"\"\"\n",
        "        model_name (str): Pretrained model being used\n",
        "        output_classes: Binary classification, so 2\n",
        "        batch_size (int): Batch size\n",
        "        num_epochs (int): Number of epochs\n",
        "        feature_extract (bool): Are we using the CNN as a feature extractor(changing only the final layer)\n",
        "                        or retraining for our problem\n",
        "\n",
        "        Adapted from the pytorch tutorials on using pre-trained models to train new classifiers.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name = None\n",
        "    output_classes = 2\n",
        "\n",
        "    def __init__(self, model_name, output_classes = 2, batch_size = 8, num_epochs=15, feature_extract=True):\n",
        "        self.model_name = model_name\n",
        "        self.output_classes = output_classes\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.feature_extract = feature_extract\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def train_model(self, model, criterion, optimizer, dataloaders, dataset_sizes, is_inception=False):\n",
        "        since = time.time()\n",
        "\n",
        "        best_model_weights = copy.deepcopy(model.state_dict())\n",
        "        best_accuracy = 0.0\n",
        "        val_acc_history = []\n",
        "\n",
        "        per_epoch_loss = []\n",
        "        per_epoch_accuracy = []\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1))\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "   \n",
        "                        if is_inception and phase == 'train':\n",
        "                            # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                            outputs, aux_outputs = model(inputs)\n",
        "                            loss1 = criterion(outputs, labels)\n",
        "                            loss2 = criterion(aux_outputs, labels)\n",
        "                            loss = loss1 + 0.4*loss2\n",
        "                        else:\n",
        "                            outputs = model(inputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                    # if phase == 'train':\n",
        "                    #     scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                if phase == 'train':\n",
        "                    per_epoch_accuracy.append(epoch_acc)\n",
        "                    per_epoch_loss.append(epoch_loss)\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                    phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_accuracy:\n",
        "                    best_accuracy = epoch_acc\n",
        "                    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "                if phase == 'val':\n",
        "                    val_acc_history.append(epoch_acc)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "            time_elapsed // 60, time_elapsed % 60))\n",
        "        print('Best val Acc: {:4f}'.format(best_accuracy))\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(best_model_weights)\n",
        "        return model, val_acc_history, per_epoch_loss, per_epoch_accuracy\n",
        "\n",
        "\n",
        "    def set_requires_grad(self, model):\n",
        "        if self.feature_extract:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def initPretrainedModel(self, inputSize):\n",
        "        model = None\n",
        "        input_size = 0\n",
        "        if self.model_name == 'alexnet' and self.feature_extract:\n",
        "            model = torchvision.models.alexnet(pretrained=True)\n",
        "            self.set_requires_grad(model)\n",
        "            num_ftrs = model.classifier[6].in_features\n",
        "            model.classifier[6] = nn.Linear(num_ftrs, self.output_classes)\n",
        "            input_size = inputSize\n",
        "\n",
        "        if self.model_name == 'inception' and self.feature_extract:\n",
        "            print(\"Initializing model: Inception_V3\")\n",
        "            model = models.inception_v3(pretrained=True)\n",
        "            self.set_requires_grad(model)\n",
        "            # Handle the auxilary net\n",
        "            num_ftrs = model.AuxLogits.fc.in_features\n",
        "            model.AuxLogits.fc = nn.Linear(num_ftrs, self.output_classes)\n",
        "            # Handle the primary net\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, self.output_classes)\n",
        "            input_size = inputSize\n",
        "        \n",
        "        if self.model_name == \"vgg\" and self.feature_extract:\n",
        "            model = models.vgg11_bn(pretrained=True)\n",
        "            self.set_requires_grad(model)\n",
        "            num_ftrs = model.classifier[6].in_features\n",
        "            model.classifier[6] = nn.Linear(num_ftrs,self.output_classes)\n",
        "            input_size = inputSize\n",
        "\n",
        "        if self.model_name == 'densenet' and self.feature_extract:\n",
        "            \"\"\"\n",
        "            Densenet 121\n",
        "            \"\"\"\n",
        "            print(\"Initializing to use pre-trained DenseNet 121 for feature extraction...\")\n",
        "            model = models.densenet121(pretrained=True)\n",
        "            self.set_requires_grad(model)\n",
        "            num_ftrs = model.classifier.in_features\n",
        "            model.classifier = nn.Linear(num_ftrs, self.output_classes)\n",
        "            input_size = inputSize\n",
        "            \n",
        "        if self.model_name == \"resnet\":\n",
        "            \"\"\"Resnet 18\n",
        "            \"\"\"\n",
        "            print(\"Initializing to use pre-trained Resnet 18 for feature extraction...\")\n",
        "            model = models.resnet18(pretrained=True)\n",
        "            self.set_requires_grad(model)\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, self.output_classes)\n",
        "            input_size = inputSize\n",
        "\n",
        "        return model\n",
        "\n",
        "    def testModel(self, dataloaders, model, classes, dataset_sizes, batch_size):\n",
        "        correct = 0\n",
        "        total = dataset_sizes['test']\n",
        "        predictions = []\n",
        "\n",
        "        y_actual = []\n",
        "        y_pred = []\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for index, (inputs, labels) in enumerate(dataloaders['test'], 0):\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                                \n",
        "                samples = dataloaders['test'].dataset.samples[index*batch_size : index*batch_size + batch_size]\n",
        "                predicted_classes = [classes[predicted[j]] for j in range(predicted.size()[0])]\n",
        "                sample_names = [s[0] for s in samples]\n",
        "                \n",
        "                predictions.extend(list(zip(sample_names, predicted_classes)))\n",
        "                # labels = labels.cpu()\n",
        "                # predicted = predicted.cpu()\n",
        "                y_actual.extend(labels.cpu().numpy())\n",
        "                y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "        try:\n",
        "            print(f\"Accuracy (Sklearn): {sklearn.metrics.accuracy_score(y_actual, y_pred)}\")\n",
        "            print(f\"F1-Score (Sklearn): {sklearn.metrics.f1_score(y_actual, y_pred)}\")\n",
        "            print(f\"Precision Score: {sklearn.metrics.precision_score(y_actual, y_pred)}\")\n",
        "            print(f\"Recall Score: {sklearn.metrics.recall_score(y_actual, y_pred)}\")\n",
        "            print(f\"\\nConfusion Matrix:\\n{sklearn.metrics.confusion_matrix(y_actual, y_pred)}\")\n",
        "            print(f\"\\nClassification Report:\\n{sklearn.metrics.classification_report(y_actual, y_pred)}\")\n",
        "        except RuntimeError:\n",
        "            print(\"Error computing metrics: \\n\", RuntimeError)\n",
        "\n",
        "        print('\\n\\nAccuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1XZjfiLcUBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer:\n",
        "\n",
        "    \"\"\"\n",
        "        Creates an stochastic gradient descent optmizer. and checks if it needs to backprop\n",
        "        the gradients.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "\n",
        "    def optimize(self, model, feature_extract, learningRate, momentum):\n",
        "        model = model.to(self.device)\n",
        "        params_to_update = model.parameters()\n",
        "        print(\"Params to learn:\")\n",
        "        if feature_extract:\n",
        "            params_to_update = []\n",
        "            for name,param in model.named_parameters():\n",
        "                if param.requires_grad == True:\n",
        "                    params_to_update.append(param)\n",
        "                    print(\"\\t\", name)\n",
        "        else:\n",
        "            for name, param in model.named_parameters():\n",
        "                if param.requires_grad == True:\n",
        "                    print(\"\\t\", name)\n",
        "\n",
        "        # optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "        optimizer_ft = optim.SGD(params_to_update, lr=learningRate, momentum=momentum)\n",
        "\n",
        "        return optimizer_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArIjvZSJbsA4",
        "colab_type": "code",
        "outputId": "37302356-0444-4d10-bdcc-b3d91100b7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    data_dir = '/content/cloudy-cycle-gans/data_small/'\n",
        "    model_name = 'densenet'\n",
        "    output_classes = 2\n",
        "    feature_extract = True\n",
        "    batch_size = 8\n",
        "    num_epochs = 20\n",
        "\n",
        "    learningRate = 0.001\n",
        "    momentum = 0.9\n",
        "\n",
        "    run_id = 'l_' + str(learningRate) + '_m_' + str(momentum)\n",
        "\n",
        "#     saved_data_structures_dir = 'saved_data_structures/'\n",
        "\n",
        "    densenetClassifier = Classifier(model_name, output_classes, batch_size, num_epochs, feature_extract)\n",
        "    model = densenetClassifier.initPretrainedModel(224)\n",
        "\n",
        "    dataloaders_dict, dataset_sizes, class_names = DataSet.initDataLoaders(data_dir, batch_size)\n",
        "    data_transforms = DataSet.setUpDataLoaderTransformers()\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in\n",
        "                      ['train', 'val', 'test']}\n",
        "\n",
        "    # Detect if we have a GPU available\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    sgdOptimizer = Optimizer(device)\n",
        "    optimizer_ft = sgdOptimizer.optimize(model, feature_extract, learningRate, momentum)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model, val_acc_history, per_epoch_loss, per_epoch_accuracy = densenetClassifier.train_model(model,\n",
        "                                                criterion,\n",
        "                                                optimizer_ft,\n",
        "                                                dataloaders_dict,\n",
        "                                                dataset_sizes)\n",
        "\n",
        "    print(f\"Validation Accuracy History:\\n{val_acc_history}\")\n",
        "    print(f\"\\nPer epoch loss:\\n{per_epoch_loss}\")\n",
        "    print(f\"\\nPer epoch accuracy:\\n{per_epoch_accuracy}\")\n",
        "\n",
        "    '''\n",
        "    # Save lists for plots:\n",
        "    print(\"Saving per_epoch_losses, per_epoch_accuracy to disk for analysis...\")\n",
        "    epoch_losses_file = 'epoch_losses_' + run_id + '.pickle'\n",
        "    with open(epoch_losses_file, 'wb') as handle:\n",
        "        pickle.dump(per_epoch_loss, handle)\n",
        "\n",
        "    epoch_accuracies_file = 'epoch_accuracies_' + run_id + '.pickle'\n",
        "    with open(epoch_accuracies_file, 'wb') as handle:\n",
        "        pickle.dump(per_epoch_accuracy, handle)\n",
        "\n",
        "    val_acc_history_file = 'val_acc_history_' + run_id + '.pickle'\n",
        "    with open(val_acc_history_file, 'wb') as handle:\n",
        "        pickle.dump(val_acc_history, handle)'''\n",
        "\n",
        "    print(\"Saving final model to disk...\")\n",
        "    save_as_name = 'densenetFeatureExtraction_' + run_id + '.pt'\n",
        "    torch.save({\n",
        "        'name': 'densenet_feature_extraction_' + run_id,\n",
        "        'epoch': num_epochs,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer_ft.state_dict(),\n",
        "    }, save_as_name)\n",
        "\n",
        "    # testing\n",
        "    print(\"Running independent test...\")\n",
        "    state = torch.load(save_as_name)\n",
        "    model.load_state_dict(state['model_state_dict'])\n",
        "    predictions = densenetClassifier.testModel(dataloaders_dict, model, class_names, dataset_sizes, batch_size=8)\n",
        "\n",
        "    # save predicted values\n",
        "    save_as_name = 'predictedLabelsDensenet_' + run_id + '.csv'\n",
        "    np.savetxt(save_as_name, predictions, fmt='%s')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing to use pre-trained DenseNet 121 for feature extraction...\n",
            "Params to learn:\n",
            "\t classifier.weight\n",
            "\t classifier.bias\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5972 Acc: 0.6901\n",
            "val Loss: 0.4010 Acc: 0.8140\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.5454 Acc: 0.7374\n",
            "val Loss: 0.4254 Acc: 0.8053\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.5330 Acc: 0.7537\n",
            "val Loss: 0.3848 Acc: 0.8267\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.5170 Acc: 0.7603\n",
            "val Loss: 0.4896 Acc: 0.7813\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.5047 Acc: 0.7589\n",
            "val Loss: 0.3557 Acc: 0.8440\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.5358 Acc: 0.7510\n",
            "val Loss: 0.3546 Acc: 0.8420\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.5268 Acc: 0.7679\n",
            "val Loss: 0.3533 Acc: 0.8533\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.5168 Acc: 0.7579\n",
            "val Loss: 0.3468 Acc: 0.8467\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.5033 Acc: 0.7696\n",
            "val Loss: 0.6314 Acc: 0.7220\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.5008 Acc: 0.7716\n",
            "val Loss: 0.3321 Acc: 0.8573\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.5107 Acc: 0.7664\n",
            "val Loss: 0.3238 Acc: 0.8700\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.5440 Acc: 0.7537\n",
            "val Loss: 0.3804 Acc: 0.8340\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.5079 Acc: 0.7679\n",
            "val Loss: 0.3591 Acc: 0.8427\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.4878 Acc: 0.7793\n",
            "val Loss: 0.3594 Acc: 0.8500\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.4959 Acc: 0.7699\n",
            "val Loss: 0.3649 Acc: 0.8440\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.5172 Acc: 0.7643\n",
            "val Loss: 0.3587 Acc: 0.8473\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.5065 Acc: 0.7763\n",
            "val Loss: 0.3259 Acc: 0.8600\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.5113 Acc: 0.7673\n",
            "val Loss: 0.3280 Acc: 0.8547\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.5094 Acc: 0.7699\n",
            "val Loss: 0.3520 Acc: 0.8467\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.5204 Acc: 0.7636\n",
            "val Loss: 0.3635 Acc: 0.8447\n",
            "\n",
            "Training complete in 14m 34s\n",
            "Best val Acc: 0.870000\n",
            "Validation Accuracy History:\n",
            "[tensor(0.8140, device='cuda:0', dtype=torch.float64), tensor(0.8053, device='cuda:0', dtype=torch.float64), tensor(0.8267, device='cuda:0', dtype=torch.float64), tensor(0.7813, device='cuda:0', dtype=torch.float64), tensor(0.8440, device='cuda:0', dtype=torch.float64), tensor(0.8420, device='cuda:0', dtype=torch.float64), tensor(0.8533, device='cuda:0', dtype=torch.float64), tensor(0.8467, device='cuda:0', dtype=torch.float64), tensor(0.7220, device='cuda:0', dtype=torch.float64), tensor(0.8573, device='cuda:0', dtype=torch.float64), tensor(0.8700, device='cuda:0', dtype=torch.float64), tensor(0.8340, device='cuda:0', dtype=torch.float64), tensor(0.8427, device='cuda:0', dtype=torch.float64), tensor(0.8500, device='cuda:0', dtype=torch.float64), tensor(0.8440, device='cuda:0', dtype=torch.float64), tensor(0.8473, device='cuda:0', dtype=torch.float64), tensor(0.8600, device='cuda:0', dtype=torch.float64), tensor(0.8547, device='cuda:0', dtype=torch.float64), tensor(0.8467, device='cuda:0', dtype=torch.float64), tensor(0.8447, device='cuda:0', dtype=torch.float64)]\n",
            "\n",
            "Per epoch loss:\n",
            "[0.5972032699244363, 0.5454370666231428, 0.5329987957307271, 0.5170194403444017, 0.5047481014302798, 0.5357939893262726, 0.5267945882592883, 0.5167553268671036, 0.5033030940507139, 0.5007635116108826, 0.5107002678513527, 0.5439940372024263, 0.5079217393738883, 0.48776276068176544, 0.4958751921611173, 0.5171854077407292, 0.5065105482297284, 0.5113259372455733, 0.5094446563380105, 0.5204342055448464]\n",
            "\n",
            "Per epoch accuracy:\n",
            "[tensor(0.6901, device='cuda:0', dtype=torch.float64), tensor(0.7374, device='cuda:0', dtype=torch.float64), tensor(0.7537, device='cuda:0', dtype=torch.float64), tensor(0.7603, device='cuda:0', dtype=torch.float64), tensor(0.7589, device='cuda:0', dtype=torch.float64), tensor(0.7510, device='cuda:0', dtype=torch.float64), tensor(0.7679, device='cuda:0', dtype=torch.float64), tensor(0.7579, device='cuda:0', dtype=torch.float64), tensor(0.7696, device='cuda:0', dtype=torch.float64), tensor(0.7716, device='cuda:0', dtype=torch.float64), tensor(0.7664, device='cuda:0', dtype=torch.float64), tensor(0.7537, device='cuda:0', dtype=torch.float64), tensor(0.7679, device='cuda:0', dtype=torch.float64), tensor(0.7793, device='cuda:0', dtype=torch.float64), tensor(0.7699, device='cuda:0', dtype=torch.float64), tensor(0.7643, device='cuda:0', dtype=torch.float64), tensor(0.7763, device='cuda:0', dtype=torch.float64), tensor(0.7673, device='cuda:0', dtype=torch.float64), tensor(0.7699, device='cuda:0', dtype=torch.float64), tensor(0.7636, device='cuda:0', dtype=torch.float64)]\n",
            "Saving final model to disk...\n",
            "Running independent test...\n",
            "Accuracy (Sklearn): 0.8306666666666667\n",
            "F1-Score (Sklearn): 0.8315649867374004\n",
            "Precision Score: 0.8271767810026385\n",
            "Recall Score: 0.836\n",
            "\n",
            "Confusion Matrix:\n",
            "[[619 131]\n",
            " [123 627]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       750\n",
            "           1       0.83      0.84      0.83       750\n",
            "\n",
            "    accuracy                           0.83      1500\n",
            "   macro avg       0.83      0.83      0.83      1500\n",
            "weighted avg       0.83      0.83      0.83      1500\n",
            "\n",
            "\n",
            "\n",
            "Accuracy of the network on the test images: 83 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfsXVbmOQleI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}